# -*- coding: utf-8 -*-
"""pytorch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lvq0SqBjc2RsteGJ4YZ6EoKBc4jqJsue
"""

import os
import torch
from torchvision import datasets, transforms
directory= "/content/Orginal/email"
transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])
image_list = []
for filename in os.listdir(directory):
    if filename.endswith(".jpg") or filename.endswith(".jpeg") or filename.endswith(".png"):
        image = datasets.folder.default_loader(os.path.join(directory, filename))
        image = transform(image)
        image_list.append(image)
image_tensor_1 = torch.stack(image_list)
print(image_tensor_1.shape)

import os
import csv
from PIL import Image

folder_path = "/content/Orginal/scientific_publication"
csv_file_path = "scientific.csv"

# Get a list of all the image files in the folder
image_files = [f for f in os.listdir(folder_path) if f.endswith(".jpg") or f.endswith(".png")]

# Create a CSV file and write the header row
with open(csv_file_path, mode="w", newline="") as csv_file:
    writer = csv.writer(csv_file)
    writer.writerow(["file_name", "width", "height", "mode", "pixels"])

    # Loop through each image file, get its metadata, and write a row to the CSV file
    for file_name in image_files:
        image_path = os.path.join(folder_path, file_name)
        with Image.open(image_path) as image:
            width, height = image.size
            mode = image.mode
            pixels = list(image.getdata())

            # Write a row to the CSV file
            writer.writerow([file_name, width, height, mode, pixels])

print("CSV file created successfully.")

import os
os.environ['TF_CPP_MIN_LOG_LEVEL']='2'
import tensorflow as tf
from tensorflow.keras import layers
from tensorflow.keras.preprocessing.image import ImageDataGenerator

img_height = 28
img_width = 28
batch_size = 2

model = Sequential()
model.add(Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)))
model.add(MaxPooling2D((2,2)))
model.add(Conv2D(64, (3,3), activation='relu'))
model.add(MaxPooling2D((2,2)))
model.add(Flatten())
model.add(Dense(64, activation='relu'))
model.add(Dense(10, activation='softmax'))

ds_train = tf.keras.preprocessing.image_dataset_from_directory('/content/Orginal/', 
                                                               labels='inferred', 
                                                               label_mode='int',
                                                               color_mode='grayscale',
                                                               batch_size=batch_size,
                                                               image_size = (img_height,img_width),
                                                               shuffle=True,
                                                               seed=123,
                                                               validation_split=0.1,
                                                               subset='training')

ds_validation = tf.keras.preprocessing.image_dataset_from_directory('/content/Orginal/', 
                                                               labels='inferred', 
                                                               label_mode='int',
                                                               color_mode='grayscale',
                                                               batch_size=batch_size,
                                                               image_size = (img_height,img_width),
                                                               shuffle=True,
                                                               seed=123,
                                                               validation_split=0.1,
                                                               subset='validation')

def augment(x, y):
  image = tf.image.random_brightness(x, max_delta=0.05)
  return image, y

ds_train = ds_train.map(augment)

for epochs  in range(10):
  for x, y in ds_train:
    pass

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

model.fit(ds_train, epochs=10, verbose = 2)